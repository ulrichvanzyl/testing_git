{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f47405",
   "metadata": {},
   "source": [
    "Only use code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da49df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Pk_generator:\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        self.file = file      \n",
    "        \n",
    "        df = pd.read_csv(file, header=None, names = range(100))\n",
    "#         df = df[0].to_str.split(',', expand=True)\n",
    "\n",
    "        # drop columns containing null-values\n",
    "        val_df = df.dropna(axis = 1)\n",
    "\n",
    "        # create nested-list containing column names\n",
    "        df_indexes = [val_df.columns]\n",
    "\n",
    "        #instantiate dataframe\n",
    "        pk_df = pd.DataFrame()\n",
    "        self.pk_df = pk_df\n",
    "        #loop over each column\n",
    "        for i in range(1, len(df_indexes[0])+1):\n",
    "\n",
    "            # concatenate columns to create multiple primary keys\n",
    "            pk_df['Primary Key '+str(i)] = val_df[df_indexes[0][:i]].astype('string').agg(lambda x: ''.join(x.values), axis=1).str.lower()\n",
    "#           \n",
    "            \n",
    "            # drop columns containing duplicate primary keys\n",
    "            if pk_df.duplicated('Primary Key ' + str(i)).any():\n",
    "                pk_df = pk_df.drop('Primary Key ' + str(i), axis = 1)\n",
    "                \n",
    "    def pks_df(self):\n",
    "        \n",
    "        if len(self.pk_df.columns)<1:\n",
    "            return 'Dataframe contains duplicates in every row'\n",
    "        else:\n",
    "            return self.pk_df\n",
    "    def pk_key(self, key_column):\n",
    "        keys = []\n",
    "        for i in self.pk_df[key_column]:\n",
    "                        \n",
    "            if len(list(i)) > 15:\n",
    "                keys.append(\"\".join(list(i)[len(list(i))-15:]))\n",
    "            else:\n",
    "                keys.append(i)\n",
    "        if len(set(keys)) == keys:\n",
    "            return keys\n",
    "        else:    \n",
    "            return 'Keys contain duplicates'\n",
    "        \n",
    "# print datafarme containing unique primary keys\n",
    "# pk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "206f88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Pk_generator('rupert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eb11202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1638"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.pks_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eebfa609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae7ecb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage unique values per column\n",
    "\n",
    "dfp = t.pks_df()\n",
    "u_valper = pd.DataFrame()\n",
    "per = []\n",
    "for col in dfp:\n",
    "    per.append(100-(len(dfp[dfp.duplicated([col])]))/len(dfp))\n",
    "\n",
    "u_valper['Percentage unique values'] = per\n",
    "u_valper.set_index(dfp.columns, drop = True)    \n",
    "u_valper['Percentage unique values'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00fa803c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percentage unique values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Percentage unique values\n",
       "0                      100.0\n",
       "18                     100.0\n",
       "17                     100.0\n",
       "16                     100.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return top five percentage\n",
    "\n",
    "u_valper.sort_values(['Percentage unique values']).iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8fac6fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Index(['Primary Key 1', 'Primary Key 2', 'Primary Key 3', 'Primary Key 4',\n",
       "        'Primary Key 5', 'Primary Key 6', 'Primary Key 7', 'Primary Key 8',\n",
       "        'Primary Key 9', 'Primary Key 10', 'Primary Key 11', 'Primary Key 12',\n",
       "        'Primary Key 13', 'Primary Key 14', 'Primary Key 15', 'Primary Key 16',\n",
       "        'Primary Key 17', 'Primary Key 18', 'Primary Key 19', 'Primary Key 20',\n",
       "        'Primary Key 21'],\n",
       "       dtype='object')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dfp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5508c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434229fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Keys contain duplicates'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.pk_key('Primary Key 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9d90d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t.pks_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5786d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = t.pks_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for i in col['Primary Key 5']:\n",
    "    if len(list(i)) > 15:\n",
    "        keys.append(\"\".join(list(i)[len(list(i))-15:]))\n",
    "return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# Your target is a dictionary {name : [scores]}\n",
    "limit = 5\n",
    "index = 0\n",
    "class error_calc:\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        # scores = defaultdict(list)\n",
    "        # scores[row[0]].extend(row[1:])\n",
    "        #     columns = []\n",
    "        length = []\n",
    "        enc = []\n",
    "        with open(file) as csvfile:\n",
    "            for row in csv.reader(csvfile):\n",
    "\n",
    "                enc.append(row.count(''\"\"'))\n",
    "    #         columns.append(row)\n",
    "                length.append(len(row))\n",
    "       \n",
    "    def encaps(self):\n",
    "        self.enc = np.array(enc)\n",
    "        return enc[enc>0]\n",
    "\n",
    "    def len_row(self):\n",
    "        self.length = np.array(length)\n",
    "        return length < length[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1025ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef95307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('dcp.csv') as f_input:\n",
    "    csv_input = csv.reader(f_input)\n",
    "    header = next(csv_input)\n",
    "    expected = len(header)\n",
    "   \n",
    "    for line_number, row in enumerate(csv_input, start=2):\n",
    "        if len(row) < expected:\n",
    "            print(line_number, row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbc2e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o = pd.read_csv('dcp.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if del_err.any():\n",
    "    print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c86487",
   "metadata": {},
   "outputs": [],
   "source": [
    "length[del_err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.iloc[del_err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37089b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7230ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('dcp.csv', header=None, sep='\\n')\n",
    "# df = df[0].str.split(',', expand=True)\n",
    "# ... do some modifications with df\n",
    "### end of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b6697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toets = Pk_generator(\"rupert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(toets.pks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1fe07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toets.pk_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "readf = open(\"rupert.csv\", 'r')\n",
    "df=readf.read()\n",
    "# print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5862d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"adcp.csv\", names=range(50))\n",
    "# f = df.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb351f5",
   "metadata": {},
   "source": [
    "Testing scripts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rupert.csv\")\n",
    "val_df = df.dropna(axis = 1)\n",
    "val_df\n",
    "# p = f[['Branch', 'Fin Proc Julian']].T.agg(\"\".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[['Division Description', 'Region Description']].astype('string').agg(lambda x: ''.join(x.values), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6af5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexes = [val_df.columns]\n",
    "df_indexes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(f.columns)):\n",
    "    print('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = pd.DataFrame()\n",
    "for i in range(1, len(df_indexes[0])+1):\n",
    "#     print(f[g[0][:i]])\n",
    "#     print(f[g[0][:i]].astype('string').agg(lambda x: ''.join(x.values), axis=1))\n",
    "    pk['Primary Key '+str(i)] = val_df[df_indexes[0][:i]].astype('string').agg(lambda x: ''.join(x.values), axis=1)\n",
    "    \n",
    "# pk.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk = pd.DataFrame()\n",
    "for i in range(1, len(g[0])+1):\n",
    "#     print(f[g[0][:i]])\n",
    "#     print(f[g[0][:i]].astype('string').agg(lambda x: ''.join(x.values), axis=1))\n",
    "    pk['Primary Key '+str(i)] = f[g[0][:i]].astype('string').agg(lambda x: ''.join(x.values), axis=1)\n",
    "    if pk.duplicated('Primary Key ' + str(i)).any():\n",
    "        pk = pk.drop('Primary Key ' + str(i), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pk.duplicated(subset='Primary Key5').any():\n",
    "#     print('Yes')\n",
    "if pk.duplicated(subset = 'Primary Key 21').any():\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pk[pk.duplicated(subset = 'Primary Key 19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from re import findall\n",
    "from itertools import combinations\n",
    "\n",
    "def nest():\n",
    "    return defaultdict(nest)\n",
    "\n",
    "d = nest()\n",
    "row_to_key = nest()\n",
    "\n",
    "with open('files.csv') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        indices = [idx for idx, i in enumerate(findall(r'[^,]+', line)) \\\n",
    "      if i == 'TRUE']\n",
    "    for j, k in combinations(indices,2):\n",
    "        if not d[j][k]:\n",
    "            d[j][k] = idx\n",
    "            row_to_key[idx] = [j, k]\n",
    "        break\n",
    "\n",
    "for row_idx in row_to_key:\n",
    "    print(' * row number', row_idx, 'can be identified by cols', row_to_key[row_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from itertools import chain, combinations\n",
    "\n",
    "\n",
    "\n",
    "def key_options(items):\n",
    "    return chain.from_iterable(combinations(items, r) for r in range(1, len(items)+1) )\n",
    "\n",
    "\n",
    "\n",
    "df = pandas.read_csv('files.csv');\n",
    "\n",
    "\n",
    "\n",
    "# iterate over all combos of headings, excluding ID for brevity\n",
    "for candidate in key_options(list(df)[1:]):\n",
    "    deduped = df.drop_duplicates(candidate)\n",
    "\n",
    "\n",
    "\n",
    "if len(deduped.index) == len(df.index):\n",
    "    print(','.join(candidate))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
